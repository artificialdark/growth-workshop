{
 "metadata": {
  "name": "",
  "signature": "sha256:61eebc3c00873b5d66d7286f913cc5b535bec581d413ce01d40459bb64e30d09"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Churn Prediction with Rolling Means\n",
      "=============================================\n",
      "\n",
      "Let's predict whether a user from ReadyChef will churn or not. Let's first remember ReadyChef's schema:\n",
      "\n",
      " <img src=\"files/schema.png\">\n",
      " \n",
      "\n",
      " \n",
      " Churn prediction starts by figuring out when a user will drop off. We detect this in many businesses usually through [rolling means](http://stackoverflow.com/questions/15771472/pandas-rolling-mean-by-time-interval). \n",
      " \n",
      " Let's first think about how we would go about predicting churn for each target.\n",
      " \n",
      "First of all, we have provided a rolling_means function for you to use below.\n",
      "\n",
      "This will allow you to pass in a set of dates to get a rolling mean for.\n",
      "\n",
      "If we want to detect drop off in visits, we will note the Visits table at the top.\n",
      "\n",
      "This contains 2 interesting columns for us. Visit duration and visit login date.\n",
      "\n",
      "Using both of those as features, we will want a boolean saying, has the user decreased activity in the last\n",
      "\n",
      "2-3 windows?\n",
      "\n",
      "Do this for both the site visit duration as well as the logins.\n",
      "\n",
      "Next, compute the moving average for the number of times they buy a meal or not.\n",
      "\n",
      "These will be your features to predict churn.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from churn_predict_ready_chef import rolling_mean\n",
      "from sqlalchemy import *\n",
      "from sqlalchemy.orm import sessionmaker\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import forjar\n",
      "#from churn_predict_ready_chef.rolling_mean import rolling_mean,churn_predict_ready_chef,util\n",
      "from  churn_predict_ready_chef.rolling_mean import rolling_mean\n",
      "from  churn_predict_ready_chef.churndata import *\n",
      "from  churn_predict_ready_chef.util import *\n",
      "from  churn_predict_ready_chef.profit_curve import *\n",
      "db = create_engine('sqlite:///forjar.db')\n",
      "\n",
      "\n",
      "metadata = MetaData(db)\n",
      "\n",
      "Session = sessionmaker(bind=db)\n",
      "\n",
      "\n",
      "session = Session()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['', '/usr/lib64/python2.7/site-packages/M2Crypto-0.21.1-py2.7-linux-x86_64.egg', '/usr/lib64/python2.7/site-packages/mrec-0.3.1-py2.7-linux-x86_64.egg', '/usr/lib64/python2.7/site-packages/ipython-2.0.0-py2.7.egg', '/usr/lib/python2.7/site-packages/pip-1.3.1-py2.7.egg', '/usr/lib/python2.7/site-packages/cmf_agent-0.1-py2.7.egg', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib64/python2.7/plat-linux2', '/usr/lib64/python2.7/lib-tk', '/usr/lib64/python2.7/lib-old', '/usr/lib64/python2.7/lib-dynload', '/usr/lib64/python2.7/site-packages', '/usr/lib64/python2.7/site-packages/PIL', '/usr/lib64/python2.7/site-packages/gst-0.10', '/usr/lib64/python2.7/site-packages/gtk-2.0', '/usr/lib/python2.7/site-packages', '/usr/lib/python2.7/site-packages/setuptools-0.6c11-py2.7.egg-info', '/usr/lib64/python2.7/site-packages/ipython-2.0.0-py2.7.egg/IPython/extensions', '.', './churn_predict_ready_chef']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's break down the steps needed to do this vectorization. Firstly, how do we get the moving averages per user on different columns?\n",
      "\n",
      "Use Pandas group by on a dataframe loaded from the database to construct a per user data frame of the visit durations.\n",
      "\n",
      "Below, make sure to initialize your df with the features to the variable named df. This is what the cells below will use to vectorize the dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\"\"\"\n",
      "Counts the users by campaign id\n",
      "\"\"\"\n",
      "user_dist = session.query(Users).join(Visit,Users.id == Visit.user_id).add_entity(Visit)\n",
      "user_df = query_to_df(session,user_dist)\n",
      "print user_df.columns\n",
      "resamp = user_df.set_index('visit_date').groupby(['Users_id']).resample('M', how='sum')\n",
      "#Visits by month for user 1, indexed by date, now go the rest of the way and calculate the moving averages for each series\n",
      "print resamp['Users_id'].fillna(0)[1]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'Users_id', u'Users_date', u'Users_Campaign_ID', u'Users_Created_Date', u'visit_id', u'visit_date', u'visit_user_id', u'visit_visit_duration'], dtype='object')\n",
        "visit_date\n",
        "2013-04-30    1\n",
        "2013-05-31    3\n",
        "2013-06-30    0\n",
        "2013-07-31    2\n",
        "2013-08-31    0\n",
        "2013-09-30    1\n",
        "2013-10-31    1\n",
        "2013-11-30    0\n",
        "2013-12-31    1\n",
        "2014-01-31    1\n",
        "2014-02-28    2\n",
        "2014-03-31    0\n",
        "2014-04-30    1\n",
        "Name: Users_id, dtype: float64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, once we have our data frame with aggregated with decreasing moving averages, let's calculate profit curves based on those features.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize_feature_index(df,label_column):\n",
      "    feature_names = []\n",
      "    X,train_index,test_index,y,y_test\n",
      "    for feature_name in df.columns.values:\n",
      "        print feature_name\n",
      "        if feature_name != label_column:\n",
      "            if feature_name not in feature_names:\n",
      "                feature_names.append(feature_name)\n",
      "    \n",
      "    X = df[feature_names].index\n",
      "    scaler = StandardScaler()\n",
      "    X = scaler.fit_transform(X)\n",
      "    train_index,test_index = train_test_split(df.index)\n",
      "    X = df[feature_names].as_matrix().astype(np.float)\n",
      "    y = df[label_column].index\n",
      "    y_test = y[test_index].astype(float)\n",
      "    return X,y,y_test,train_index,test_index\n",
      " \n",
      "\n",
      "X,y,y_test,train_index,test_index = vectorize_feature_index(df,'Event_Type')\n",
      "profit_curve(classifiers)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-45-10f6fda11472>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorize_feature_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Event_Type'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprofit_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}